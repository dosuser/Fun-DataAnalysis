{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting (Exercise ver.)\n",
    "\n",
    "**scope**: \n",
    "- ÏãúÍ∞ÑÏóê ÎåÄÌïú Ìï®Ïàò, ÏãúÍ∞ÑÏóê Îî∞Î•∏ Î≥ÄÌôîÏóê Ï£ºÏïà,  Ïù∏Í≥º Í¥ÄÍ≥ÑX\n",
    "- Data Wrangling for time-series in Python\n",
    "- self projecting(o), cause and effect(X)\n",
    "- uni-variate(o), multi-variate(x)\n",
    "- Time-series Basics; seasonality, trend, residual, statrionary/non-stationary process\n",
    "- Time-series forecasting using ARIMA (Box Jenkins Approach, ACF, PACF)\n",
    "\n",
    "**requirements**:\n",
    "- python 2.7 or 3\n",
    "- statsmodel 0.8.0   \n",
    "(**anaconda user** -> `conda install -c taugspurger statsmodels=0.8.0` Ï∞∏Í≥†: https://anaconda.org/search?q=statsmodels%20   \n",
    "// **pip user** -> `pip install statsmodels==0.8.rc1` )\n",
    " \n",
    "- (Jupyter Kernel) (http://stackoverflow.com/questions/28831854/how-do-i-add-python3-kernel-to-jupyter-ipython)\n",
    "\n",
    "**reference**:   \n",
    "[1] [Seasonal ARIMA with Python](http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/)  \n",
    "[2] [A Complete Tutorial on Time Series Modeling in R](https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/)  \n",
    "[3] [A comprehensive beginner‚Äôs guide to create a Time Series Forecast (with Codes in Python)](https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/)  \n",
    "[4] [Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïù¥Ïñ∏Ïä§ Ïä§Ïø®/ ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑù](https://www.datascienceschool.net/view-notebook/e0c935b3f55c4302b0fb0c93986562cd/)  \n",
    "[5] [ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Ïùò ÌÜµÍ≥ÑÏ†Å Î∂ÑÏÑù Î∞©Î≤ï](https://www.google.co.kr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwjJkr3qqvDQAhVIyLwKHUgSDKoQFgggMAA&url=https%3A%2F%2Fbigdata.kookmin.ac.kr%2F%3Fmodule%3Dfile%26act%3DprocFileDownload%26file_srl%3D351%26sid%3D43ea21693d9f550e5e39869d5ce52adc&usg=AFQjCNFeXfnfSgzHQHDP85VZTBUvi4wy0Q&sig2=uZvEKrxxd_rr4Gv4lOB7Yw)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Ïù¥Ìï¥\n",
    "\n",
    "ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏùÑ ÏúÑÌï¥ÏÑúÎäî Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Ïùò ÏöîÏÜå Î∞è Ï†ïÏÉÅ/ÎπÑÏ†ïÏÉÅ Í≥ºÏ†ïÏóê ÎåÄÌïú Ïù¥Ìï¥Í∞Ä ÌïÑÏöîÌïòÎã§.\n",
    "\n",
    "![](figure/TS_pattern.png)\n",
    "*(Ï∂úÏ≤ò: [5])*\n",
    "\n",
    "### 1.1. ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ ÏöîÏÜå \n",
    "\n",
    "- **Ï∂îÏÑ∏(Trend)**: Ïû•Í∏∞Ï†ÅÏúºÎ°ú ÎÇòÌÉÄÎÇòÎäî Î≥ÄÎèô Ìå®ÌÑ¥\n",
    "- **Í≥ÑÏ†àÏÑ±(Seasonal)**: Ï£º,Ïõî,Î∂ÑÍ∏∞,Î∞òÍ∏∞ Îã®ÏúÑ Îì± Ïù¥ÎØ∏ ÏïåÎ†§ÏßÑ ÏãúÍ∞ÑÏùò Ï£ºÍ∏∞Î°ú ÎÇòÌÉÄÎÇòÎäî Ìå®ÌÑ¥ \n",
    "- **Ï£ºÍ∏∞(Cyclic)**: ÏµúÏÜå 2 ÎÖÑ Îã®ÏúÑÎ°ú ÎÇòÌÉÄÎÇòÎäî Í≥†Ï†ïÎêú Í∏∞Í∞ÑÏù¥ ÏïÑÎãå Ïû•Í∏∞Ï†ÅÏù∏ Î≥ÄÎèô\n",
    "- **ÎûúÎç§ÏöîÏÜå (random/residual/remainder)**\n",
    "\n",
    "![](https://anomaly.io/wp-content/uploads/2015/12/time-series-decomposition-seasonal-trend.png)\n",
    "\n",
    "![](https://anomaly.io/wp-content/uploads/2015/12/multiplicative-decompose.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Ï†ïÏÉÅ Î∞è ÎπÑÏ†ïÏÉÅ Í≥ºÏ†ï Î™®Ìòï Staionary & Non-Stationary \n",
    "\n",
    "\n",
    "ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÏãúÍ≥ÑÏó¥ Î∂ÑÏÑùÏùò Ïö©Ïù¥ÏÑ±ÏùÑ ÏúÑÌï¥ ÏïÑÎûòÏôÄ Í∞ôÏù¥ ÎπÑÏ†ïÏÉÅÍ≥ºÏ†ï Î™®Ìòï(ùëå )Ïóê Îî∞Î•¥Îäî ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ \"\n",
    "ÎòêÌïú Ï∂îÏ†ï Í∞ÄÎä•Ìïú Í≤∞Ï†ïÎ°†Ï†Å Ï∂îÏÑ∏Ìï®Ïàò ($ùëì_{t}$ , trend) ÏôÄ ÌôïÎ•† Ï†ïÏÉÅÍ≥ºÏ†ï($ ùëã_{t} $)Ïùò Ìï©ÏúºÎ°ú Í∞ÄÏ†ïÌïòÍ≥† Î∂ÑÏÑùÌïúÎã§.\n",
    "\n",
    "$$\\begin{align*} & y_{t}\\sim f_{\\left( t\\right) }+X_{t}\\end{align*} $$\n",
    "\n",
    "Îî∞ÎùºÏÑú ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏóêÏÑú Ï†ïÏÉÅÍ≥ºÏ†ï Î™®ÌòïÏùò ÌäπÏÑ± Î∞è Î∂ÑÏÑùÎ∞©Î≤ïÎì§ÏùÑ Ïù¥Ìï¥ÌïòÎäî Í≤ÉÏù¥ Ïö∞ÏÑ†Ï†ÅÏúºÎ°ú ÏöîÍµ¨ÎêúÎã§. Îã§ÏùåÏùÄ Ï†ïÏÉÅ ÏãúÍ≥ÑÏó¥ Î™®ÌòïÍ≥º ÎπÑÏ†ïÏÉÅ ÏãúÍ≥ÑÏó¥ Î™®ÌòïÏùò ÌäπÏßï ÎπÑÍµêÏù¥Îã§.\n",
    "\n",
    "[ÏÉÅÏÑ∏ÏÑ§Î™Ö Ï∞∏Í≥†](https://www.datascienceschool.net/view-notebook/0ddd47967585403ab8b4cb60d0e420f6/)\n",
    "\n",
    "** i.ÏãúÍ∞Ñ Ï∂îÏù¥Ïóê Îî∞Î•∏ ÌèâÍ∑†Í∞íÏùò Î∂àÎ≥ÄÏó¨Î∂Ä**  \n",
    "Ï†ïÏÉÅÍ≥ºÏ†ï - ÌèâÍ∑†ÏùÄ ÏãúÍ∞ÑÏóê Îî∞Îùº Î≥ÄÌôîÌïòÎäî Ìï®ÏàòÍ∞Ä ÏïÑÎãàÎã§.;ÏùºÏ†ïÌïú ÌèâÍ∑† else ÎπÑÏ†ïÏÉÅÍ≥ºÏ†ï\n",
    "\n",
    "$$ E(y_{t}) = \\mu $$\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Mean_nonstationary.png)\n",
    "\n",
    "** ii.ÏãúÍ∞ÑÏ∂îÏù¥Ïóê Îî∞Î•∏ Î∂ÑÏÇ∞Ïùò Î∂àÎ≥ÄÏó¨Î∂Ä**  \n",
    "Ï†ïÏÉÅÍ≥ºÏ†ï - Î∂ÑÏÇ∞ÏùÄ ÏãúÍ∞ÑÏóê Îî∞Îùº Î≥ÄÌôîÌïòÎäî Ìï®ÏàòÍ∞Ä ÏïÑÎãàÎã§.;ÏùºÏ†ïÌïú Î∂ÑÏÇ∞  else ÎπÑÏ†ïÏÉÅÍ≥ºÏ†ï\n",
    "\n",
    "$$ var(y_{t}) = \\sigma^{2} $$\n",
    "\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Var_nonstationary.png)\n",
    "\n",
    "**C.ÏãúÏ†êÍ∞ÑÏùò Í≥µÎ∂ÑÏÇ∞**  \n",
    "Í≥µÎ∂ÑÏÇ∞ÏùÄ tÍ∞Ä ÏïÑÎãå sÏóê ÏùòÏ°¥Ìï®\n",
    "$$ cov(y_{t}, y_{t+s}) = cov(y_{t}, y_{t-s}) = \\gamma_{s} $$\n",
    "$$ cov(X,Y) = E((X-\\mu)(Y-\\upsilon))  $$\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Cov_nonstationary.png)\n",
    "\n",
    "\n",
    "Î≥∏ Ïû•ÏóêÏÑú ÏÜåÍ∞úÌïòÎäî ÌÜµÍ≥ÑÏ†Å ÏãúÍ≥ÑÏó¥ Ï∂îÏ†ï Î™®ÌòïÎì§ÏùÄ ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞Î•º Ï†ïÏÉÅÌôîÏãúÌÇ® Î™®Ìòï ÏúÑÏóêÏÑú ÏÑ§Í≥ÑÎêòÏñ¥ ÏûàÏúºÎØÄÎ°ú, ÌïÑÏàòÏ†ÅÏúºÎ°ú Îç∞Ïù¥ÌÑ∞Î•º Ï†ïÏÉÅÌôî ÏãúÌÇ§Îäî Í≥ºÏ†ïÏù¥ ÌïÑÏöîÌïòÎã§.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Framework\n",
    "\n",
    "ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÏïÑÎûòÏôÄ Í∞ôÏùÄ Î∞©Î≤ïÏúºÎ°ú ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑùÏùÑ ÏßÑÌñâÌïúÎã§.  \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/flowchart.png)\n",
    "\n",
    "ÎòêÎäî [ÎßÅÌÅ¨: ÌôïÎ•† Í≥ºÏ†ï Î™®ÌòïÏùÑ Ï∂îÏ†ïÌïòÎäî Î∞©Î≤ï](https://www.datascienceschool.net/view-notebook/e4b52228ac5749418d51409fdc4f9cef/)ÏôÄ Í∞ôÏùÄ Ï†àÏ∞®Î•º ÌÜµÌï¥ ÌôïÎ•†Î™®ÌòïÏùÑ Ï∂îÏ†ïÌï† Ïàò ÏûàÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Pandas Í∏∞Ï¥à\n",
    "\n",
    "Î≥∏ Ï†àÏùÄ [6]Python for Finance Ïùò ÎÇ¥Ïö©ÏùÑ Í∏∞Ï¥àÎ°ú Ìï®.  \n",
    "[Ï∞∏Í≥†: pandas cheat sheet](https://s3.amazonaws.com/quandl-static-content/Documents/Quandl+-+Pandas,+SciPy,+NumPy+Cheat+Sheet.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a vector with random numbers\n",
    "a = np.random.standard_normal((9,4))\n",
    "print ('>>> a=\\n',a.round(6))\n",
    "\n",
    "# create dataframe\n",
    "fun_df = pd.DataFrame(a)\n",
    "print ('>>> fun_df=\\n',fun_df)\n",
    "\n",
    "# create DatetimeIndex objects\n",
    "dates = pd.date_range('2016-1-1',periods=9,freq='M')\n",
    "print ('>>> dates=\\n',dates)\n",
    "\n",
    "# set index of df with 'dates'\n",
    "fun_df.index = dates\n",
    "print ('>>> fun_df.index=\\n',fun_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Basic methods: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index values\n",
    "fun_df.index\n",
    "\n",
    "# columns \n",
    "fun_df.columns\n",
    "\n",
    "# select via index\n",
    "fun_df.ix['2016-02-29'] \n",
    "fun_df.ix[fun_df.index[1:3]]\n",
    "fun_df[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** LAMBDA func, apply()** - [lambda - Ï∞∏Í≥†](https://wikidocs.net/64), [apply - Ï∞∏Í≥†](http://chrisalbon.com/python/pandas_apply_operations_to_dataframes.html)\n",
    "\n",
    "![](http://nbviewer.jupyter.org/github/h3imdallr/TIL-datascience/blob/master/ipynb_gitHub/images/non-builtin.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply()\n",
    "fun_df.apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert another column (dimension expansion)\n",
    "fun_df['new'] = np.zeros(9)\n",
    "fun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_df.columns = ['A','B','C','D','E']\n",
    "\n",
    "# sum\n",
    "fun_df.sum()\n",
    "fun_df.cumsum()\n",
    "\n",
    "# mean\n",
    "fun_df.mean()\n",
    "\n",
    "# std\n",
    "fun_df.std()\n",
    "\n",
    "# numpy universal functions\n",
    "np.sqrt(fun_df)\n",
    "\n",
    "# general stats\n",
    "fun_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fun_df.plot()\n",
    "# plt.plot(fun_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Groupby Operations **  \n",
    "\n",
    "SQLÏùò group select , ÏóëÏÖÄÏùò pivot tableÍ≥º ÎπÑÏä∑Ìïú Í∏∞Îä•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_df['Quarter'] = ['Q1','Q1','Q1','Q2','Q2','Q2','Q3','Q3','Q3']\n",
    "fun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = fun_df.groupby('Quarter')\n",
    "groups #groupby Í∞ùÏ≤¥ÏûÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups.mean()\n",
    "groups.max()\n",
    "groups.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÎëêÍ∞úÏùò Ïó¥ÏùÑ ÎèôÏãúÏóê Í∏∞Ï§ÄÏúºÎ°ú ÌïòÎäî Í∑∏Î£π ÏßÄÏ†ïÎèÑ Í∞ÄÎä•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fun_df['Odd_Even'] = ['Odd','Even','Odd','Even','Odd','Even','Odd','Even','Odd']\n",
    "fun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = fun_df.groupby(['Quarter','Odd_Even'])\n",
    "groups.size()\n",
    "groups.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 EDA; ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏ÌïòÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm  \n",
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Wrangling__: \n",
    "dropna, column name, DF slicing, date_range, type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.1-1) : data/data/portland-oregon-average-monthly.csv ÌååÏùº Î∂àÎü¨Ïò§Í∏∞ & 'Month' ÌñâÏùÑ indexÎ°ú ÏÑ§Ï†ï (hint: pandas read_csv())\n",
    "df = \n",
    "#preprocessing\n",
    "# (task 2.1-2): dataframeÏóêÏÑú NaN(not a number) Ï†úÍ±∞ÌïòÍ∏∞\n",
    "# (task 2.1-3): column Ïù¥Î¶Ñ 'ridership'ÏúºÎ°ú Î≥ÄÍ≤Ω\n",
    "# (task 2.1-4): dataframe Ï†úÏùº ÎßàÏßÄÎßâÌñâ Ï†úÍ±∞ÌïòÍ∏∞\n",
    "# ÌôïÏù∏\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.1-5): dataframe ÏãúÍ∞ÅÌôî \n",
    "# ERROR --> index type should be 'datetime'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* change df.index as datetime object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.1-6): datetime Í∞ùÏ≤¥Î°ú index Î≥ÄÍ≤ΩÌïòÍ∏∞\n",
    "# OPTION(1)\n",
    "# OPTION(2)\n",
    "\n",
    "# ÌôïÏù∏: \n",
    "type(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.1-7): DF time slicing- 1960/3/1 ~ 1961/7/1 ÏùºÏóê Ìï¥ÎãπÌïòÎäî dataframe Ï∂îÏ∂úÌïòÍ∏∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* change type of dataframe's column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.1-8): df Ïùò 'ridership' ÌñâÏùÑ int ÌÉÄÏûÖÏúºÎ°ú Î≥ÄÍ≤ΩÌïòÍ∏∞\n",
    "# OPTION(1)\n",
    "# OPTION(2) lambda, apply \n",
    "\n",
    "# ÌôïÏù∏: \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.1-9): dataframe ÏãúÍ∞ÅÌôî ( again )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal Decomposition (STL)\n",
    "\n",
    "ÎÇ®ÏùÄ residual valueÎ•º Ï∂îÏ∂úÌï®ÏúºÎ°úÏç®, time-independentÌïú time-seriesÎ•º ÎΩëÏùå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.1 - 10): seasonal_decompose\n",
    "decomposition = seasonal_decompose(df['ridership'], freq=12)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seasonal Trend Decomposition (STL) ÌôúÏö©:\n",
    "- Anomaly Deteciton (residualÌôúÏö©)\n",
    "- Stationarize \n",
    "- ÏãúÍ≥ÑÏó¥ Ìå®ÌÑ¥ ÎπÑÍµê (ÏòàÏãú, ÏïÑÎûò)\n",
    "\n",
    "![](figure/STL_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ÏãúÍ≥ÑÏó¥ Îç∞Ïù¥ÌÑ∞ Ï†ïÏÉÅÌôî ÌïòÍ∏∞\n",
    "\n",
    "### Ï†ïÏÉÅÏÑ± ÌôïÏù∏ stationarity check\n",
    "ÏùºÎ∞òÏ†ÅÏúºÎ°ú Îç∞Ïù¥ÌÑ∞Í∞Ä stationaryÌïú Í≤ΩÏö∞Îäî Í±∞Ïùò ÏóÜÏùå. \n",
    "Ï†ïÏÉÅÏÑ±ÏùÑ TestÌïòÍ∏∞ ÏúÑÌï¥ÏÑú ÎëêÍ∞ÄÏßÄ Î∞©Î≤ï ÏÇ¨Ïö©   \n",
    "\n",
    "**(1) ÎààÏúºÎ°ú ÏßÅÍ¥ÄÏ†Å ÌôïÏù∏ ~ STL, Rolling statistics(moving average)    \n",
    "(2) Dickey-FUller test [ÎßÅÌÅ¨](https://www.datascienceschool.net/view-notebook/ebb638fc880145b9adeef8dfa630f067/)  **\n",
    "\n",
    "ÏïÑÎûòÎäî  Dickey-Fuller test ÏôÄ ÎçîÎ∂àÏñ¥  trendÎ•º Ï∂îÏ∂úÌïòÎäî Î∞©Î≤ïÏ§ë ÌïòÎÇòÏù∏ rolling statisticsÎ•º Ïù¥Ïö©Ìï¥ÏÑú ÎèôÏãúÏóê Ï†ïÏÉÅÏÑ±ÏùÑ Í≤ÄÏÇ¨ÌïòÎäî Î∞©Î≤ïÏù¥Îã§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "\n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=12)\n",
    "    rolstd = pd.rolling_std(timeseries, window=12)\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "\n",
    "    plt.legend(loc='best'); plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('<Results of Dickey-Fuller Test>')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4],\n",
    "                         index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.2 - 1): Ï†ïÏÉÅÏÑ± Ï≤¥ÌÅ¨ (hint: test_stationarity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Judgment:   \n",
    "(null-hypothesis: TS is non-stationary)  \n",
    "p-value < 0.05: reject null-hypothesis --> Stationary  \n",
    "p-value > 0.05: accept --> non-Stationary  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ï†ïÏÉÅÌôî Stationarize\n",
    "\n",
    "ÎπÑÏ†ïÏÉÅ ÌôïÎ•†Í≥ºÏ†ïÏùÑ Ï†ïÏÉÅ ÌôïÎ•† Í≥ºÏ†ïÏúºÎ°ú Î≥ÄÌôòÌïòÎäî Î∞©Î≤ïÏùÄ Ïó¨Îü¨Í∞ÄÏßÄ [[1]](http://people.duke.edu/~rnau/whatuse.htm), [[2]](https://www.datascienceschool.net/view-notebook/3f485c426a4b49fc9de95a02137ca6b4/)Í∞Ä ÏûàÏúºÎ©∞, Ï£ºÏñ¥ÏßÑ Îç∞Ïù¥ÌÑ∞Ïóê Îî∞Îùº Í∞ÄÏû• Ìö®Ïú®Ï†ÅÏù∏ Î∞©Î≤ïÏù¥ Îã§Î•¥Í±∞ÎÇò ÌòºÌï©ÌïòÏó¨ ÏÇ¨Ïö©ÌïúÎã§. (ÏÉÅÏÑ∏ÎÇ¥Ïö© ÎßÅÌÅ¨Ï∞∏Ï°∞)\n",
    "Ïó¨Í∏∞ÏÑúÎäî ÏßßÍ≤å ÏÑ∏Í∞ÄÏßÄÏóê ÎåÄÌï¥ÏÑú ÏÜåÍ∞úÌïúÎã§. \n",
    "- **Ï∞®Î∂Ñ(differencing)**: 1Ï∞®Ï∞®Î∂Ñ. Trend Ï†úÍ±∞ÌïòÎäîÎç∞ Ïö©Ïù¥ $\\Delta y_{t} = y_{t} - y_{t-1}$\n",
    "- **Î°úÍ∑∏Î≥ÄÌôò(lograithm)**: ÌëúÏ§ÄÌé∏Ï∞®Í∞Ä ÏûêÎ£åÏùò ÌÅ¨Í∏∞Ïóê ÎπÑÎ°ÄÌïòÏó¨ Ï¶ùÍ∞ÄÌï†Îïå\n",
    "- **Box-Cox Î≥ÄÌôò**: Ï†ïÍ∑úÎ∂ÑÌè¨Í∞Ä ÏïÑÎãå ÏûêÎ£åÎ•º Ï†ïÍ∑úÎ∂ÑÌè¨Î°ú Î≥ÄÌôò. \n",
    "\n",
    "\n",
    "Ïó¨Í∏∞ÏÑúÎäî Ï∞®Î∂ÑÏùÑ Ïù¥Ïö©ÌïòÏó¨ Ï†ïÏÉÅÌôîÎ•º ÌïúÎã§.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (task 2.2 - 1): Ï∞®Î∂ÑÌïòÍ∏∞ ; y_{t}-y_{t-1}; \n",
    "# OPTION1 - hint: shift()\n",
    "# OPTION2 - hint: diff()\n",
    "\n",
    "df['first_difference'] = ~~~ \n",
    "test_stationarity(df.first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ï¢ÄÎçî ÎÇòÏùÄ ÏàòÏ§ÄÏùò Ï†ïÏÉÅÌôîÎ•º ÏúÑÌï¥, ÎèÑÌïú seasonal Ìå®ÌÑ¥ÏùÑ Ï¢ÄÎçî Î™ÖÌôïÌûà Î≥¥Í≥† Ïã∂Í≥†, long-termÏóêÏÑúÎèÑ Ïûò ÎÇ®ÏïÑÏûàÍ≤å ÌïòÍ∏∞ ÏúÑÌï¥ÏÑú seasonaly differencing ÏùÑ Ï†ÅÏö©ÌïúÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['seasonal_first_difference'] = df['first_difference'] - df['first_difference'].shift(12)  \n",
    "test_stationarity(df.seasonal_first_difference.dropna(inplace=False))\n",
    "\n",
    "# Else: \n",
    "# df['log_first_difference'] = df.riders_log - df.riders_log.shift(1)\n",
    "# df['seasonal_difference'] = df.riders - df.riders.shift(12)  \n",
    "# df['log_seasonal_difference'] = df.riders_log - df.riders_log.shift(12) \n",
    "# df['log_seasonal_first_difference'] = df.log_first_difference - df.log_first_difference.shift(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-valueÍ∞Ä Îçî ÎÜíÏïÑÏßÑ Ï†êÏóêÏÑú seasonal first differenceÎ•º ÌÜµÌï¥ ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú dataÎ•º Ï†ïÏÉÅÌôî ÏãúÏº∞Îã§Í≥† ÌåêÎã®ÌïúÎã§.Ï∂îÍ∞ÄÏ†ÅÏúºÎ°ú Î°úÍ∑∏Î≥ÄÌôò(`df[~] = np.log(df[~])`)ÎèÑ Ìï† Ïàò ÏûàÏúºÎÇò, Î≥∏ Í≤ΩÏö∞ÏóêÏÑúÎäî Î∂ÑÏÑùÌõÑ ÌÅ¨Í≤å ÎÇòÏïÑÏßÄÏßÄ ÏïäÏïòÎã§.\n",
    "ÎòêÌïú Ï∂îÍ∞ÄÎ°ú Ï∂îÏÑ∏Î•º Ï∂îÏ†ïÌïòÏó¨ Ï†úÍ±∞ÌïòÎäî Í∏∞Î≤ï[(ÎßÅÌÅ¨: Í≤∞Ï†ïÎ°†Ï†Å Ï∂îÏÑ∏/Îã§Ìï≠Ïãù Ï∂îÏÑ∏/ Í≥ÑÏ†àÏÑ± Ï∂îÏÑ∏ Ï∂îÏ†ï)](https://www.datascienceschool.net/view-notebook/240b62a8927043c79b5384536e42f99d/)Îì§Ïù¥ ÏûàÏúºÎÇò, Ï∂©Î∂ÑÌûà Ï†ïÏÉÅÌôî ÎêòÏóàÎã§Í≥† ÌåêÎã®ÌïòÍ≥† Î≥∏ Î∂ÑÏÑùÏóêÏÑúÎäî ÏÜåÍ∞úÌïòÏßÄ ÏïäÎäîÎã§."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.3 Î™®ÏàòÏ∂îÏ†ï;  ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞(Î™®ÌòïÏ∞®Ïàò) ÎèÑÏ∂ú\n",
    "\n",
    "### ARIMA Î™®Îç∏Ïùò Í∞úÎÖê\n",
    "\n",
    "- Ï∂úÏ≤ò: [Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïù¥Ïñ∏Ïä§ Ïä§Ïø®](https://www.datascienceschool.net/view-notebook/d5226389a8414583a45fb47e1e1cf6fb/)\n",
    "\n",
    "** a. Ï†ïÏÉÅÍ≥ºÏ†ï ÌôïÎ•† Î™®Ìòï(1/2) - General Linear Process Model **  \n",
    "Ï†ïÏÉÅÌôïÎ•† Í≥ºÏ†ïÏóêÏÑú Í∞ÄÏû• ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÏÇ¨Ïö©ÎêòÎäî Î™®ÌòïÏùÄ ÏùºÎ∞òÏÑ†Ìòï ÌôïÎ•† Í≥ºÏ†ï Î™®Ìòï(General Linear Process Model)Ïù¥Îã§. Ìï¥Îãπ Î™®ÌòïÏùÄ ÏãúÍ≥ÑÏó¥Ïù¥ [Í∞ÄÏö∞ÏãúÏïà Î∞±ÏÉâÏû°Ïùå](https://www.datascienceschool.net/view-notebook/6b963e771dc54f8c8cb23437274a86d6/) ($e_{t}$)Ïùò ÌòÑÏû¨Í∞íÍ≥º Í≥ºÍ±∞Í∞íÎì§Ïùò ÏÑ†ÌòïÏ°∞Ìï©ÏúºÎ°ú Ïù¥Î£®Ïñ¥Ï†∏ ÏûàÎã§Í≥† Í∞ÄÏ†ï. $\\psi $ Îäî Í∞ÄÏ§ëÍ≥ÑÏàò(weight coefficient). \n",
    "\n",
    "$$ Y_t = e_t + \\psi_1 e_{t-1}  + \\psi_2 e_{t-2}  + \\psi_1 e_{t-3}  + \\cdots $$\n",
    "\n",
    "ÏúÑ Î™®ÌòïÏùò Î∏îÎü≠ Îã§Ïù¥Ïñ¥Í∑∏Îû®ÏùÄ Îã§ÏùåÍ≥º Í∞ôÎã§.\n",
    "\n",
    "![](figure/glpm.png)\n",
    "\n",
    "** b. Ï†ïÏÉÅÍ≥ºÏ†ï ÌôïÎ•† Î™®Ìòï (2/2) MA, AR, ARMA **\n",
    "\n",
    "ÏùºÎ∞ò ÏÑ†Ìòï ÌôïÎ•† Í≥ºÏ†ï Î™®ÌòïÏùÄ Í≥ÑÏàòÏùò ÌäπÏÑ±Ïóê Îî∞Îùº Îã§ÏùåÍ≥º Í∞ôÏùÄ ÌïòÏúÑ Î™®ÌòïÏúºÎ°ú Î∂ÑÎ•òÎêúÎã§.\n",
    "\n",
    "- **MA (Moving Average) Î™®Ìòï**: Î∞±ÏÉâ Ïû°ÏùåÏùò ÌòÑÏû¨ Í∞íÍ≥º Í≥ºÍ±∞ Í∞í Ï§ë Ïú†Ìïú(finite)Í∞úÏùò Í∞íÏóê ÎåÄÌïú ÏÑ†Ìòï Í∞ÄÏ§ëÌï©(linear weighted summation)ÏúºÎ°ú ÎÇòÌÉÄÎÇòÎäî ÌôïÎ•† Í≥ºÏ†ï.qÏ∞®ÏàòÏóê ÎåÄÌï¥ÏÑú MA(q)Î°ú ÌëúÍ∏∞  \n",
    "\n",
    "$$ Y_t = e_t - \\theta_1 e_{t-1}  - \\theta_2 e_{t-2} - \\cdots - \\theta_q e_{t-q} $$\n",
    "![](figure/ma.png)\n",
    "\n",
    "- **AR (Auto-Regressive) Î™®Ìòï**: ÏûêÍ∏∞ ÏûêÏã†Ïùò Í≥ºÍ±∞Í∞íÏóê ÏùòÏ°¥Ï†ÅÏù∏ Î™®Ìòï. Î∞±ÏÉâ Ïû°ÏùåÏùò ÌòÑÏû¨Í∞íÍ≥º ÏûêÍ∏∞ ÏûêÏã†Ïùò Í≥ºÍ±∞Í∞íÏùò ÏÑ†Ìòï Í∞ÄÏ§ëÌï©ÏúºÎ°ú Ïù¥Î£®Ïñ¥ÏßÑ Ï†ïÏÉÅ ÌôïÎ•† Î™®Ìòï. pÏ∞®ÏàòÏùò ARÎ™®Ìòï: AR(p)\n",
    "\n",
    "$$ Y_t = \\phi_1 Y_{t-1}  + \\phi_2 Y_{t-2}  + \\cdots + \\phi_p Y_{t-p}  + e_t $$\n",
    "\n",
    "![](figure/ar.png)\n",
    "\n",
    "Ïù¥ Î™®ÌòïÏù¥ ÏÑ†ÌòïÌôïÎ•†Í≥ºÏ†ïÏùÑ Îî∞Î•¥Îäî Í≤ÉÏùÄ ÏïÑÎûòÏôÄ Í∞ôÏù¥ Ï¶ùÎ™Ö Ìï† Ïàò ÏûàÎã§.   \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "Y_t \n",
    "&=& \\phi Y_{t-1} + e_t \\\\\n",
    "&=& \\phi \\left( \\phi Y_{t-2} + e_{t-1} \\right) + e_t \\\\\n",
    "&=& \\phi^2 Y_{t-2} + \\phi e_{t-1} + e_t \\\\\n",
    "&=& \\phi^2  \\left( \\phi Y_{t-3} + e_{t-2} \\right)  + \\phi e_{t-1} + e_t \\\\\n",
    "&=& \\phi^3 Y_{t-3} + \\phi^2 e_{t-2}  + \\phi e_{t-1} + e_t \\\\\n",
    "&\\vdots& \\\\\n",
    "&=& e_t + \\phi e_{t-1} + \\phi^2 e_{t-2} + \\phi^3 e_{t-3} + \\cdots  \\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "- **ARMA (Auto-Regressive Moving Average) Î™®Ìòï**: ARMA(p,q) Î™®ÌòïÏùÄ AR(p) Î™®ÌòïÍ≥º MA(q) Î™®ÌòïÏùò ÌäπÏßïÏùÑ Î™®Îëê Í∞ÄÏßÄÎäî Î™®ÌòïÏùÑ ÎßêÌï®.  \n",
    "\n",
    "$$ Y_t = \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + \\cdots + \\phi_p Y_{t-p} + e_t - \\theta_1 e_{t-1} - \\theta_2 e_{t-2} \\cdots  - \\theta_q e_{t-q} $$\n",
    "\n",
    "\n",
    "** c. ÎπÑÏ†ïÏÉÅÍ≥ºÏ†ïÌôïÎ•†Î™®Ìòï -  ARIMA **\n",
    "\n",
    " ÎπÑÏ†ïÏÉÅ Í≥ºÏ†ï Î™®Ìòï Ï§ë Í∞ÄÏû• ÎåÄÌëúÏ†ÅÏù∏ Î™®ÌòïÏúºÎ°ú,  ARMA Î™®ÌòïÏùÑ ÎàÑÏ†ÅÌïú Î™®ÌòïÏù¥Îã§. ÏãúÍ≥ÑÏó¥  $Y_{t}$ ÏùÑ Ï∞®Î∂ÑÌïú Í≤∞Í≥ºÎ°ú ÎßåÎì§Ïñ¥ÏßÑ ÏãúÍ≥ÑÏó¥ $\\nabla Y_t = Y_t - Y_{t-1}$  Ïù¥ ARMA Î™®ÌòïÏùÑ Îî∞Î•¥Î©¥ ÏõêÎûòÏùò ÏãúÍ≥ÑÏó¥ $Y_{t}$ Î•º ARIMA(Autoregressive Integrated Moving Average) Î™®ÌòïÏù¥ÎùºÍ≥† ÌïúÎã§.\n",
    "\n",
    "ÎßåÏïΩ  $d$ Î≤à Ï∞®Î∂ÑÌïú ÌõÑÏóêÏïº ÏãúÍ≥ÑÏó¥  $\\nabla Y_t$ Í∞Ä ARMA(p,q) Î™®ÌòïÏùÑ Îî∞Î•∏Îã§Î©¥ Ï†ÅÎ∂Ñ Ï∞®Ïàò(order of integration)Í∞Ä  $d$ Ïù∏ ARIMA Î™®ÌòïÏúºÎ°ú ARIMA(p, d, q)Î°ú ÌëúÍ∏∞ÌïúÎã§.  $q=0$ Ïù∏ Í≤ΩÏö∞ÏóêÎäî ARI(p,d), $p=0$ Ïù∏ Í≤ΩÏö∞ÏóêÎäî IMA(d,q)Î°ú ÌëúÍ∏∞ÌïúÎã§.\n",
    "\n",
    "\n",
    "### ARIMA Î™®Ìòï Ï∞®Ïàò Í≤∞Ï†ï  \n",
    "\n",
    "ÏïûÏÑú ÏÑ§Î™ÖÌïú ARIMAÏùò p, d, q Î™®ÌòïÏ∞®ÏàòÎäî ÏïÑÎûòÏôÄ Í∞ôÏùÄ Î∞©Î≤ïÏúºÎ°ú Í≤∞Ï†ï Ìï† Ïàò ÏûàÎã§. [(ÏÉÅÏÑ∏Ï∞∏Ï°∞)](https://www.datascienceschool.net/view-notebook/b39ccd2da3e64d6e91981e23e01816c4/) \n",
    "\n",
    "- **Augmented Dickey-Fuller Í≤ÄÏ†ï** : d\n",
    "- **ÏûêÍ∏∞ÏÉÅÍ¥ÄÍ≥ÑÏàò Ìï®Ïàò(ACF)**: q\n",
    "- **Ìé∏ÏûêÍ∏∞ÏÉÅÍ¥ÄÍ≥ÑÏàò Ìï®Ïàò(PACF)** : p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Î™®Ìòï        | ACF  | PACF  |\n",
    "| :-------: |:-------------:| :-------------:|\n",
    "| AR(p)| ÏßÄÏàòÌï®ÏàòÏ†ÅÏúºÎ°ú Í∞êÏÜåÌïòÍ±∞ÎÇò Ï†êÏ∞® ÏßÑÌè≠Ïù¥ Ï∂ïÏÜåÎêòÎäî ÏÇ¨Ïù∏ Í≥°ÏÑ†Ïùò ÌååÎèôÏùÑ ÎÇòÌÉÄÎÇ¥Í±∞ÎÇò ÎòêÎäî ÏñëÏ™ΩÎ™®Îëê ÎÇòÌÉÄÎÇ® (ÏãúÏ∞®Í∞Ä Ï¶ùÍ∞ÄÌï®Ïóê Îî∞Îùº0 ÏúºÎ°ú Í∏âÏÜçÌûà Ï†ëÍ∑º) |p Ïùò ÏãúÏ∞®ÍπåÏßÄ Ïú†ÏùòÏÑ± ÏûàÎäî Í∞íÏùÑ ÎÇòÌÉÄÎÇ¥Í≥† Ïù¥ÌõÑ ÏÜåÎ©∏Ìï®|\n",
    "| MA(q)| q Ïùò ÏãúÏ∞®ÍπåÏßÄ Ïú†ÏùòÏÑ± ÏûàÎäî Í∞íÏùÑ ÎÇòÌÉÄÎÇ¥Í≥† Ïù¥ÌõÑ ÏÜåÎ©∏Ìï® | ÏßÄÏàòÌï®ÏàòÏ†ÅÏúºÎ°ú Í∞êÏÜåÌïòÍ±∞ÎÇò Ï†êÏ∞®ÏßÑÌè≠Ïù¥ Ï∂ïÏÜåÎêòÎäî ÏÇ¨Ïù∏ Í≥°ÏÑ†Ïùò ÌååÎèôÏùÑ ÎÇòÌÉÄÎÇ¥Í±∞ÎÇò ÎòêÎäî ÏñëÏ™Ω Î™®Îëê ÎÇòÌÉÄÎÇ® (ÏãúÏ∞®Í∞Ä Ï¶ùÍ∞ÄÌï®Ïóê Îî∞Îùº 0 ÏúºÎ°úÍ∏âÏÜçÌûàÏ†ëÍ∑º)|\n",
    "| ARMA(p,q)| ÏßÄÏàòÌï®ÏàòÏ†ÅÏúºÎ°ú Í∞êÏÜåÌïòÍ±∞ÎÇò Ï†êÏ∞® ÏßÑÌè≠Ïù¥ Ï∂ïÏÜåÎêòÎäî ÏÇ¨Ïù∏ Í≥°ÏÑ†Ïùò ÌååÎèôÏùÑ ÎÇòÌÉÄÎÇ¥Í±∞ÎÇò ÎòêÎäî ÏñëÏ™Ω Î™®Îëê ÎÇòÌÉÄÎÇ® (ÏãúÏ∞®Í∞Ä Ï¶ùÍ∞ÄÌï®Ïóê Îî∞Îùº 0 ÏúºÎ°ú Í∏âÏÜçÌûà Ï†ëÍ∑º) | ÏßÄÏàòÌï®ÏàòÏ†ÅÏúºÎ°ú Í∞êÏÜåÌïòÍ±∞ÎÇò Ï†êÏ∞® ÏßÑÌè≠Ïù¥ Ï∂ïÏÜåÎêòÎäî ÏÇ¨Ïù∏ Í≥°ÏÑ†Ïùò ÌååÎèôÏùÑ ÎÇòÌÉÄÎÇ¥Í±∞ÎÇò ÎòêÎäî ÏñëÏ™Ω Î™®Îëê ÎÇòÌÉÄÎÇ® (ÏãúÏ∞®Í∞Ä Ï¶ùÍ∞ÄÌï®Ïóê Îî∞Îùº 0 ÏúºÎ°ú Í∏âÏÜçÌûà Ï†ëÍ∑º) |\n",
    "![](figure/parameter.png)\n",
    "![ARIMA](figure/ARIMA.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Î≥∏ Î∂ÑÏÑùÏóêÏÑúÎäî Ïó∞Îã®ÏúÑ(12Í∞úÏõî) Ï∞®Ïù¥Î°ú Ï†ïÏÉÅÌôî ÏãúÏºúÏÑú, Seasonal ARIMA Î™®Îç∏Î°ú Î∂ÑÎ•òÎê®.  \n",
    "> Seasonal ARIMA Î™®ÌòïÏùÄ Ï§ÑÏó¨ÏÑú SARIMAÎùºÍ≥† ÌïòÍ∏∞ÎèÑ ÌïúÎã§. Îã®Ïàú SARIMA Î™®ÌòïÏùÄ Í∞Å Í≥ÑÏ†àÏóê Îî∞Î•∏ ÎèÖÎ¶ΩÏ†ÅÏù∏ ARIMA Î™®ÌòïÏù¥ Ìï©Ï≥êÏ†∏ ÏûàÎäî Î™®ÌòïÏù¥Îã§. Í∏∞Ï°¥ ARIMA(p,d,q) Î™®ÌòïÏóê Í≥ÑÏ†àÏÑ± Ï£ºÍ∏∞Î•º ÎÇòÌÉÄÎÇ¥Îäî Ï∞®Ïàò sÍ∞Ä Ï∂îÍ∞ÄÏ†ÅÏúºÎ°ú ÌïÑÏöîÌïòÍ∏∞ ÎïåÎ¨∏Ïóê SARIMA(P,D,Q,s) Î°ú ÌëúÍ∏∞ÌïúÎã§.  \n",
    "sÏùò Í∞íÏùÄ ÏõîÎ≥Ñ Í≥ÑÏ†àÏÑ±ÏùÑ ÎÇòÌÉÄÎÇº ÎïåÎäî  $s=12$ Í∞Ä ÎêòÍ≥† Î∂ÑÍ∏∞Î≥Ñ Í≥ÑÏ†àÏÑ±ÏùÑ ÎÇòÌÉÄÎÇº ÎïåÎäî  $s=4$ Í∞Ä ÎêúÎã§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(df.seasonal_first_difference.iloc[13:], lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(df.seasonal_first_difference.iloc[13:],lags=40,ax=ax2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÏúÑ Í∑∏ÎûòÌîÑÏóêÏÑú, 1Ï∞® Ï∞®Î∂ÑÌïú Í∞í(first_diff)Ïù¥ t+1..t+12ÍπåÏßÄ AR(0), MR(0), d=1.  \n",
    "\n",
    "12Î≤àÏß∏ÏóêÏÑú +->- SAR(1), SMA(1)\n",
    "\n",
    "ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú **SARIMA (0,1,0)X(1,1,1,12) **  \n",
    "\n",
    "SARIMA Î™®ÌòïÏ∂îÏ†ï [ÏòàÏãú](https://www.datascienceschool.net/view-notebook/602e62fc1c544ffcb43c2c7e1484dc14/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Î™®Îç∏ ÏàòÎ¶Ω  \n",
    "ÏúÑ Îã®Í≥ÑÏóêÏÑú ÌôïÏ†ïÌïú Î™®Îç∏Ïùò Î™®ÌòïÏ∞®ÏàòÎ•º Ïù¥Ïö©ÌïòÏó¨, (Seasonal) ARIMA Î™®Îç∏ÏùÑ ÏÉùÏÑ±ÌïúÎã§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod = sm.tsa.SARIMAX(df['ridership'],order=(0,1,0), seasonal_order=(1,1,1,12))\n",
    "results = mod.fit()\n",
    "print (results.summary())\n",
    "\n",
    "# import statsmodels.api as sm  \n",
    "# mod = sm.tsa.statespace.SARIMAX(df['ridership'], trend='n', order=(0,1,0), seasonal_order=(0,1,1,12))\n",
    "# results = mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌèâÍ∞Ä\n",
    "Î™®ÌòïÏù¥ ÌõåÎ•≠ÌïòÎã§Î©¥ Ïù¥ Í∞íÏùÄ ÎçîÏù¥ÏÉÅ ÏòàÏ∏°Ìï† Ïàò ÏûàÎäî ÏöîÏÜåÍ∞Ä Ï†ÑÌòÄ ÏóÜÎäî ÏãúÍ≥ÑÏó¥ Ï¶â, Í∞ÄÏö∞ÏãúÏïà Î∞±ÏÉâ Ïû°ÏùåÏóê Í∞ÄÍπåÏö¥ ÌäπÏÑ±ÏùÑ Î≥¥Ïó¨Ïïº ÌïúÎã§.  \n",
    "Î∞±ÏÉâÏû°Ïùå: Î∞±ÏÉâ Ïû°Ïùå  $e$ ÏùÄ ÌôïÎ•† Í≥ºÏ†ïÏùÑ Íµ¨ÏÑ±ÌïòÎäî Î™®Îì† Í∞úÎ≥Ñ ÌôïÎ•† Î≥ÄÏàò  $e_{t}$ Îì§Ïù¥ ÏÑúÎ°ú ÎèÖÎ¶ΩÏù¥Í≥†(independent) ÎèôÏùºÌïú ÌôïÎ•† Î∂ÑÌè¨Î•º Îî∞Î•¥Îäî(identically distributed) ÌôïÎ•† Í≥ºÏ†ïÏùÑ ÎßêÌïúÎã§. \n",
    "\n",
    "Î∞±ÏÉâ Ïû°ÏùåÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ ÌäπÏÑ±ÏùÑ ÎßåÏ°±ÌïúÎã§.\n",
    "\n",
    "- Ï†ïÏÉÅ Í≥ºÏ†ï(stictly stationary process)Ïù¥Îã§.\n",
    "\n",
    "- ÏãúÏ∞®(lag)Í∞Ä 0Ïùº Í≤ΩÏö∞, ÏûêÍ∏∞Í≥µÎ∂ÑÏÇ∞ÏùÄ ÌôïÎ•† Î∂ÑÌè¨Ïùò Î∂ÑÏÇ∞Ïù¥ ÎêòÍ≥† ÏãúÏ∞®Í∞Ä 0Ïù¥ ÏïÑÎãå Í≤ΩÏö∞, ÏûêÍ∏∞Í≥µÎ∂ÑÏÇ∞ÏùÄ 0Ïù¥Îã§.  \n",
    "\n",
    "$$\\gamma_l = \\begin{cases} \\text{Var}[e_t] & \\;\\; \\text{ for } l = 0 \\\\  0 & \\;\\; \\text{ for }  l \\neq 0 \\end{cases}$$\n",
    "\n",
    "- ÏãúÏ∞®(lag)Í∞Ä 0Ïùº Í≤ΩÏö∞, ÏûêÍ∏∞ÏÉÅÍ¥ÄÍ≥ÑÏàòÎäî 1Ïù¥ ÎêòÍ≥† ÏãúÏ∞®Í∞Ä 0Ïù¥ ÏïÑÎãå Í≤ΩÏö∞, ÏûêÍ∏∞ÏÉÅÍ¥ÄÍ≥ÑÏàòÎäî 0Ïù¥Îã§.  \n",
    "\n",
    "$$\\rho_l = \\begin{cases} 1 & \\;\\; \\text{ for } l = 0 \\\\  0 & \\;\\; \\text{ for }  l \\neq 0 \\end{cases}$$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.plot_diagnostics();\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.5  ÏãúÍ≥ÑÏó¥ ÏòàÏ∏°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['forecast'] = results.predict(start = len(df)-12, end= len(df), dynamic= True)  \n",
    "df[['ridership', 'forecast']].plot()\n",
    "df[-12:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÏòàÏ∏° Í∏∞Í∞ÑÏù¥ Í∏∏Ïñ¥ÏßàÏàòÎ°ù Î∂ÄÏ†ïÌôïÌï¥ Ïßà Ïàò ÏûàÏùå (ÏïÑÎûò, 24Í∞úÏõî)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['forecast'] = results.predict(start = len(df)-24, end= len(df), dynamic= True)  \n",
    "df[['ridership', 'forecast']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime.strptime(\"1969-07-01\", \"%Y-%m-%d\") \n",
    "# >1982-07-01 00:00:00\n",
    "date_list = [start + relativedelta(months=x) for x in range(0,12)]\n",
    "#> 1982/7/1,8/1, ... 1983/6/1\n",
    "\n",
    "future_df = pd.DataFrame(index=date_list, columns= df.columns)\n",
    "new_df = pd.concat([df, future_df]) #concatenated  dataframe\n",
    "# print(new_df.head(),'\\n...\\n',new_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['forecast'] = results.predict(start = len(df), end = len(df)+11, dynamic= True)  \n",
    "new_df[['ridership', 'forecast']].ix[-48:].plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (df.forecast[-12:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Study\n",
    "- [Seasonal ARIMA Îã§Î•∏ ÏòàÏ†ú](https://www.datascienceschool.net/view-notebook/8c4f6ad9487149ca872374bbbf098e5f/)\n",
    "- [ARIMAX](https://www.datascienceschool.net/view-notebook/3e70dc86adb841b58736522c491eb770/)\n",
    "- [LSTMÏùÑ Ïù¥Ïö©Ìïú ÏãúÍ≥ÑÏó¥ Ï∂îÏ†ï](http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)\n",
    "- anomaly detection ÏòàÏ†ú\n",
    "- [Bayesian Time Series Forecasting](http://multithreaded.stitchfix.com/blog/2016/04/21/forget-arima/)\n",
    "\n",
    "(End of Doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
